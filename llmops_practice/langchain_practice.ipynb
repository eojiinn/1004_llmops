{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "import langgraph\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "langchain_tracing = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "aws_region = os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='2024년 미국 대선의 주요 후보들은 아직 확정되지 않았습니다. 하지만 현재 상황을 보면:\\n\\n1. 민주당:\\n   - 조 바이든 현 대통령이 재선에 도전할 가능성이 높습니다.\\n\\n2. 공화당:\\n   - 도널드 트럼프 전 대통령이 출마를 선언했습니다.\\n   - 론 드샌티스 플로리다 주지사가 유력한 후보로 거론되고 있습니다.\\n   - 니키 헤일리 전 유엔 대사도 출마를 선언했습니다.\\n\\n그 외에도 여러 정치인들이 출마를 고려하거나 선언할 수 있습니다. 대선이 다가올수록 후보군이 더 명확해질 것입니다. 정확한 후보 명단은 각 당의 예비선거를 통해 결정될 것입니다.', additional_kwargs={'usage': {'prompt_tokens': 27, 'completion_tokens': 307, 'total_tokens': 334}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, response_metadata={'usage': {'prompt_tokens': 27, 'completion_tokens': 307, 'total_tokens': 334}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, id='run-5ad98a79-6743-4b2a-af4e-847675210d2a-0', usage_metadata={'input_tokens': 27, 'output_tokens': 307, 'total_tokens': 334})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Bedrock 모델 설정\n",
    "model = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    model_kwargs=dict(temperature=0)\n",
    ")\n",
    "\n",
    "# 모델 호출 확인\n",
    "example_result = model.invoke([HumanMessage(content=\"다음 미국 대선 후보는 누구인가요?\")])\n",
    "example_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024년 미국 대선의 주요 후보들은 아직 확정되지 않았습니다. 하지만 현재 상황을 보면:\n",
      "\n",
      "1. 민주당:\n",
      "   - 조 바이든 현 대통령이 재선에 도전할 가능성이 높습니다.\n",
      "\n",
      "2. 공화당:\n",
      "   - 도널드 트럼프 전 대통령이 출마를 선언했습니다.\n",
      "   - 론 드샌티스 플로리다 주지사가 유력한 후보로 거론되고 있습니다.\n",
      "   - 니키 헤일리 전 유엔 대사도 출마를 선언했습니다.\n",
      "\n",
      "그 외에도 여러 정치인들이 출마를 고려하거나 선언할 수 있습니다. 대선이 다가올수록 후보군이 더 명확해질 것입니다. 정확한 후보 명단은 각 당의 예비선거를 통해 결정될 것입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 출력 파서 설정\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 파서 확인\n",
    "parsed_result = parser.invoke(example_result)\n",
    "print(parsed_result)  # 출력: '안녕!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BasePromptTemplate.invoke() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 프롬프트 템플릿\u001b[39;00m\n\u001b[1;32m      7\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[1;32m      8\u001b[0m     [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, system_template), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{text}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m prompt_result \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(prompt_result\u001b[38;5;241m.\u001b[39mto_messages())\n",
      "\u001b[0;31mTypeError\u001b[0m: BasePromptTemplate.invoke() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 시스템 템플릿\n",
    "system_template = (\n",
    "    \"당신은 질문에 답하는 어시스턴트입니다. \"\n",
    "    \"다음 문서에서 제공된 내용을 사용하여 질문에 답변하세요. \"\n",
    "    \"모르면 모른다고 말하세요. 최대 세 문장으로 간결하게 답하세요.\"\n",
    "    \"\\\\n\\\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_template), \n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# # 템플릿 호출\n",
    "# prompt_result = prompt_template.invoke()\n",
    "# print(prompt_result.to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메모리(+체인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 텍스트 스플리터 설정 (1000자 단위로 문서를 나누고, 중첩 200자 적용)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 벡터 스토어에 임베딩 적용 및 문서 저장\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=splits, embedding=BedrockEmbeddings(\n",
    "        model_id='amazon.titan-embed-text-v1',\n",
    "    )\n",
    ")\n",
    "\n",
    "# 리트리버 생성\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# 새로운 그래프 정의\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# # 호출 함수\n",
    "# def call_model(state: MessagesState):\n",
    "#     # 체인 생성\n",
    "#     chain = prompt_template | model | parser\n",
    "#     response = chain.invoke(state[\"messages\"])\n",
    "#     return {\"messages\": response}\n",
    "\n",
    "# # 노드 및 메모리 설정(메모리와 컴파일)\n",
    "# workflow.add_edge(START, \"model\")\n",
    "# workflow.add_node(\"model\", call_model)\n",
    "# memory = MemorySaver()\n",
    "# app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# def create_qna_chain(model, prompt_template, parser):\n",
    "#     return prompt_template | model | parser\n",
    "\n",
    "qna_chain = create_stuff_documents_chain(model, prompt_template, parser)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, qna_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "langchain_tracing = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "aws_region = os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock  # Bedrock 모델 사용\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Bedrock 모델 설정\n",
    "model = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='Translate the following into korean:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 시스템 메시지 템플릿 생성\n",
    "system_template = \"Translate the following into {language}:\"\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "\n",
    "# 템플릿 호출\n",
    "prompt_result = prompt_template.invoke({\"language\": \"korean\", \"text\": \"hi\"})\n",
    "print(prompt_result.to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트, 모델, 파서를 결합한 체인 생성\n",
    "# chain = prompt_template | model | parser\n",
    "chain = model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is a broad field of computer science focused on creating intelligent machines that can perform tasks that typically require human intelligence. Here's a brief overview of AI:\n",
      "\n",
      "1. Definition: AI refers to systems or machines that mimic human intelligence to perform tasks and can iteratively improve themselves based on the information they collect.\n",
      "\n",
      "2. Types of AI:\n",
      "   - Narrow AI: Designed for specific tasks (e.g., virtual assistants, image recognition)\n",
      "   - General AI: Hypothetical AI with human-like intelligence across various domains\n",
      "   - Super AI: Theoretical AI surpassing human intelligence in all areas\n",
      "\n",
      "3. Key components:\n",
      "   - Machine Learning: Algorithms that improve through experience\n",
      "   - Deep Learning: Advanced machine learning using neural networks\n",
      "   - Natural Language Processing: Enabling computers to understand and generate human language\n",
      "   - Computer Vision: Allowing machines to interpret and understand visual information\n",
      "\n",
      "4. Applications:\n",
      "   - Virtual assistants (e.g., Siri, Alexa)\n",
      "   - Autonomous vehicles\n",
      "   - Predictive analytics\n",
      "   - Robotics\n",
      "   - Healthcare diagnostics\n",
      "   - Personalized recommendations\n",
      "\n",
      "5. Techniques:\n",
      "   - Neural networks\n",
      "   - Decision trees\n",
      "   - Genetic algorithms\n",
      "   - Fuzzy logic\n",
      "   - Expert systems\n",
      "\n",
      "6. Challenges:\n",
      "   - Ethical concerns (privacy, bias, job displacement)\n",
      "   - Data quality and quantity\n",
      "   - Interpretability of complex AI systems\n",
      "   - Ensuring AI safety and reliability\n",
      "\n",
      "7. Future prospects:\n",
      "   - Continued integration into various industries\n",
      "   - Advancements in AI-human collaboration\n",
      "   - Potential development of more general AI capabilities\n",
      "\n",
      "AI is a rapidly evolving field with far-reaching implications for technology, society, and the future of human-machine interaction."
     ]
    }
   ],
   "source": [
    "result = chain.stream(\"Explain AI\")\n",
    "for chunk in result:\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence. These tasks include learning, problem-solving, perception, language understanding, reasoning, and planning.\n",
      "\n",
      "Key aspects of AI include:\n",
      "\n",
      "1. Machine Learning: The ability of AI systems to improve their performance on a specific task through experience, without being explicitly programmed.\n",
      "\n",
      "2. Deep Learning: A subset of machine learning that uses artificial neural networks to model and process complex patterns in data.\n",
      "\n",
      "3. Natural Language Processing (NLP): The ability of AI to understand, interpret, and generate human language.\n",
      "\n",
      "4. Computer Vision: The ability to analyze and understand visual information from the world.\n",
      "\n",
      "5. Robotics: The integration of AI with physical machines to perform tasks in the real world.\n",
      "\n",
      "6. Expert Systems: AI programs designed to solve complex problems by reasoning through bodies of knowledge, represented mainly as if-then rules.\n",
      "\n",
      "7. Planning and Decision-making: The ability to make decisions and create plans to achieve specific goals.\n",
      "\n",
      "AI can be categorized into two main types:\n",
      "\n",
      "1. Narrow or Weak AI: Designed and trained for a specific task (e.g., virtual assistants, image recognition software).\n",
      "\n",
      "2. General or Strong AI: Hypothetical AI with human-like cognitive abilities across a wide range of tasks.\n",
      "\n",
      "AI has numerous applications across various industries, including healthcare, finance, transportation, education, and entertainment. As the field continues to advance, it raises important ethical, social, and economic questions about the impact of AI on society and the future of work.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke(\"Explain AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI, or Artificial Intelligence, refers to the development of computer systems that can perform tasks that typically require human intelligence. These tasks include:\\n\\n1. Learning and problem-solving\\n2. Visual perception\\n3. Speech recognition\\n4. Decision-making\\n5. Language translation\\n\\nAI systems are designed to mimic human cognitive functions and can improve their performance over time through experience and data analysis. There are two main types of AI:\\n\\n1. Narrow or Weak AI: Designed for a specific task or range of tasks (e.g., virtual assistants, image recognition)\\n\\n2. General or Strong AI: Hypothetical AI with human-like consciousness and ability to perform any intellectual task\\n\\nAI technologies include machine learning, deep learning, neural networks, and natural language processing. These are used in various applications such as:\\n\\n- Autonomous vehicles\\n- Healthcare diagnostics\\n- Financial trading\\n- Personalized recommendations\\n- Robotics\\n\\nAs AI continues to advance, it has the potential to revolutionize many aspects of our lives and industries, while also raising important ethical and societal questions.', \"Machine Learning (ML) is a subset of Artificial Intelligence (AI) that focuses on developing algorithms and statistical models that enable computer systems to improve their performance on a specific task through experience, without being explicitly programmed. In other words, it's a method of data analysis that automates analytical model building.\\n\\nHere are some key points about Machine Learning:\\n\\n1. Learning from data: ML systems learn from data, identifying patterns and making decisions with minimal human intervention.\\n\\n2. Types of learning:\\n   - Supervised Learning: The algorithm learns from labeled data.\\n   - Unsupervised Learning: The algorithm finds patterns in unlabeled data.\\n   - Reinforcement Learning: The algorithm learns through interaction with an environment.\\n\\n3. Applications: ML is used in various fields, including:\\n   - Image and speech recognition\\n   - Natural language processing\\n   - Recommendation systems\\n   - Fraud detection\\n   - Autonomous vehicles\\n   - Medical diagnosis\\n\\n4. Algorithms: Common ML algorithms include:\\n   - Linear and logistic regression\\n   - Decision trees and random forests\\n   - Support Vector Machines (SVM)\\n   - Neural networks and deep learning\\n   - K-means clustering\\n\\n5. Iterative process: ML models improve over time as they are exposed to more data.\\n\\n6. Data-driven: The quality and quantity of data significantly impact the performance of ML models.\\n\\n7. Interdisciplinary field: ML combines elements from computer science, statistics, and mathematics.\\n\\n8. Continuous evolution: As technology advances, new ML techniques and applications are constantly being developed.\\n\\nMachine Learning is transforming various industries by enabling computers to learn from experience and perform tasks that traditionally required human intelligence.\"]\n"
     ]
    }
   ],
   "source": [
    "inputs = [\"What is AI?\", \"What is Machine Learning?\"]\n",
    "results = chain.batch(inputs=inputs)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_stream_example(texts):\n",
    "    for text in texts:\n",
    "        async for chunk in chain.astream(input=text):\n",
    "            print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI\n",
      ",\n",
      " or\n",
      " Artificial Intelligence, refers\n",
      " to the simulation\n",
      " of human\n",
      " intelligence in\n",
      " machines that\n",
      " are\n",
      " program\n",
      "med to think an\n",
      "d learn\n",
      " like humans. Key\n",
      " aspects\n",
      " of AI include:\n",
      "\n",
      "\n",
      "1\n",
      ". Machine\n",
      " Learning: The\n",
      " ability of AI\n",
      " systems to learn from\n",
      " data\n",
      " and improve\n",
      " their performance over time\n",
      " without\n",
      " explicit\n",
      " programming.\n",
      "\n",
      "\n",
      "2. Natural\n",
      " Language Processing (N\n",
      "LP): Enabling\n",
      " machines to understand,\n",
      " interpret\n",
      ", and generate human\n",
      " language.\n",
      "\n",
      "\n",
      "3. Computer\n",
      " Vision: Allowing\n",
      " machines to interpret\n",
      " and understand visual information\n",
      " from\n",
      " the\n",
      " world.\n",
      "\n",
      "\n",
      "4.\n",
      " Robotics: The\n",
      " integration of AI into\n",
      " physical machines\n",
      " to\n",
      " perform\n",
      " tasks.\n",
      "\n",
      "\n",
      "5. Expert\n",
      " Systems: AI\n",
      " programs\n",
      " designe\n",
      "d to solve\n",
      " complex\n",
      " problems by\n",
      " mim\n",
      "icking human expertise\n",
      " in\n",
      " specific\n",
      " domains.\n",
      "\n",
      "6\n",
      ". Neural\n",
      " Networks: Computational\n",
      " models inspired by the\n",
      " human brain's\n",
      " structure\n",
      " and function\n",
      ".\n",
      "\n",
      "7.\n",
      " Deep\n",
      " Learning: A\n",
      " subset\n",
      " of machine learning that\n",
      " uses\n",
      " multi\n",
      "-lay\n",
      "ered neural networks to\n",
      " analyze\n",
      " various\n",
      " factors\n",
      " of\n",
      " data\n",
      ".\n",
      "\n",
      "AI\n",
      " can\n",
      " be categor\n",
      "ized into two\n",
      " main\n",
      " types:\n",
      "\n",
      "\n",
      "1.\n",
      " Narrow or\n",
      " Weak\n",
      " AI: Designe\n",
      "d for\n",
      " a\n",
      " specific task (\n",
      "e.g.,\n",
      " virtual\n",
      " assist\n",
      "ants, image\n",
      " recognition).\n",
      "\n",
      "\n",
      "2. General\n",
      " or Strong AI:\n",
      " Hypoth\n",
      "etical AI with\n",
      " human\n",
      "-like\n",
      " consciousness\n",
      " and ability\n",
      " to solve\n",
      " any\n",
      " intellectual\n",
      " task.\n",
      "\n",
      "AI\n",
      " has applications\n",
      " in various fields,\n",
      " including\n",
      " healthcare, finance,\n",
      " transportation\n",
      ", education, an\n",
      "d entertainment\n",
      ",\n",
      " an\n",
      "d continues\n",
      " to evol\n",
      "ve rapidly.\n",
      "\n",
      "\n",
      "\n",
      "Machine Learning (\n",
      "ML) is a\n",
      " subset\n",
      " of\n",
      " Artificial Intelligence (\n",
      "AI) that focuses\n",
      " on developing algorithms\n",
      " an\n",
      "d statistical\n",
      " models that enable\n",
      " computer\n",
      " systems to improve\n",
      " their\n",
      " performance on a\n",
      " specific\n",
      " task through\n",
      " experience,\n",
      " without\n",
      " being explicitly\n",
      " programmed. In\n",
      " other words, it\n",
      "'s\n",
      " a\n",
      " metho\n",
      "d of\n",
      " teaching computers to learn\n",
      " from\n",
      " data and make decisions\n",
      " or\n",
      " predictions base\n",
      "d on that learning.\n",
      "\n",
      "\n",
      "Key\n",
      " aspects of Machine Learning\n",
      " include\n",
      ":\n",
      "\n",
      "1.\n",
      " Data\n",
      ": ML\n",
      " algorithms rely\n",
      " on large amounts\n",
      " of data\n",
      " to learn patterns an\n",
      "d make predictions.\n",
      "\n",
      "\n",
      "2. Training\n",
      ": The\n",
      " process\n",
      " of feeding\n",
      " data into the\n",
      " algorithm to\n",
      " help\n",
      " it learn an\n",
      "d improve its performance.\n",
      "\n",
      "\n",
      "3. Models\n",
      ": Mathematical\n",
      " representations\n",
      " of real\n",
      "-world processes\n",
      " that\n",
      " the\n",
      " algorithm creates\n",
      " base\n",
      "d on the training\n",
      " data.\n",
      "\n",
      "4\n",
      ". Predictions\n",
      ": Once\n",
      " trained, ML\n",
      " models can make predictions\n",
      " or decisions on\n",
      " new,\n",
      " unseen data.\n",
      "\n",
      "\n",
      "5.\n",
      " Continuous\n",
      " improvement\n",
      ": ML models\n",
      " can be updated with\n",
      " new data to improve\n",
      " their accuracy\n",
      " over\n",
      " time.\n",
      "\n",
      "There\n",
      " are three\n",
      " main types\n",
      " of Machine Learning:\n",
      "\n",
      "\n",
      "1.\n",
      " Supervised Learning: The\n",
      " algorithm learns\n",
      " from labeled data\n",
      ",\n",
      " where both\n",
      " input\n",
      " and desire\n",
      "d output are provide\n",
      "d.\n",
      "\n",
      "\n",
      "2.\n",
      " Unsupervise\n",
      "d Learning: The algorithm\n",
      " learns from unlab\n",
      "eled data,\n",
      " finding\n",
      " patterns and structures\n",
      " on\n",
      " its own.\n",
      "\n",
      "\n",
      "3. Reinfor\n",
      "cement Learning: The\n",
      " algorithm learns through\n",
      " interaction\n",
      " with an environment,\n",
      " receiving\n",
      " feedback in\n",
      " the form of rewards\n",
      " or penalties\n",
      ".\n",
      "\n",
      "Machine\n",
      " Learning has\n",
      " numerous\n",
      " applications across\n",
      " various industries\n",
      ", including:\n",
      "\n",
      "\n",
      "-\n",
      " Healthcare\n",
      " (\n",
      "disease\n",
      " diagnosis, drug\n",
      " discovery)\n",
      "\n",
      "- Finance (\n",
      "frau\n",
      "d detection, stock market\n",
      " prediction)\n",
      "-\n",
      " Marketing\n",
      " (customer segmentation\n",
      ", recommendation\n",
      " systems\n",
      ")\n",
      "-\n",
      " Autonomous\n",
      " vehicles\n",
      "\n",
      "- Natural\n",
      " Language\n",
      " Processing\n",
      "\n",
      "- Computer\n",
      " Vision\n",
      "\n",
      "\n",
      "As technology\n",
      " advances, Machine Learning\n",
      " continues\n",
      " to play an\n",
      " increasingly important role in\n",
      " many\n",
      " aspects of our daily\n",
      " lives an\n",
      "d various\n",
      " industries.\n",
      "\n",
      "\n",
      "\n",
      "Hi\n",
      " there! How\n",
      " can\n",
      " I assist you today\n",
      "?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await async_stream_example([\"What is AI?\", \"What is Machine Learning?\", \"Say Hi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Runnable 인터페이스 코드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runnable 인터페이스 정의\n",
    "class Runnable:\n",
    "    def invoke(self, input):\n",
    "        raise NotImplementedError(\"The 'invoke' method must be implemented!\")\n",
    "\n",
    "    def stream(self, input):\n",
    "        raise NotImplementedError(\"The 'stream' method must be implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatModel response to: Tell me about AI\n",
      "Error: The 'stream' method must be implemented!\n"
     ]
    }
   ],
   "source": [
    "# Runnable 인터페이스를 상속받은 클래스\n",
    "class ChatModel(Runnable):\n",
    "    def invoke(self, input):\n",
    "        return f\"ChatModel response to: {input}\"\n",
    "\n",
    "# stream 메서드가 구현되지 않음\n",
    "chat_model = ChatModel()\n",
    "\n",
    "# invoke 메서드는 정상적으로 작동\n",
    "print(chat_model.invoke(\"Tell me about AI\"))\n",
    "\n",
    "# stream 메서드는 구현되지 않았으므로 에러 발생\n",
    "try:\n",
    "    for chunk in chat_model.stream(\"Tell me about AI\"):\n",
    "        print(chunk)\n",
    "except NotImplementedError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatModel response to: Tell me about AI\n",
      "Streaming: Tell\n",
      "Streaming: me\n",
      "Streaming: about\n",
      "Streaming: AI\n"
     ]
    }
   ],
   "source": [
    "# 모든 메서드를 구현한 ChatModel 클래스\n",
    "class ChatModel(Runnable):\n",
    "    def invoke(self, input):\n",
    "        return f\"ChatModel response to: {input}\"\n",
    "\n",
    "    def stream(self, input):\n",
    "        for word in input.split():\n",
    "            yield f\"Streaming: {word}\"\n",
    "\n",
    "# 이번에는 모든 메서드가 구현되었으므로 에러가 발생하지 않음\n",
    "chat_model = ChatModel()\n",
    "\n",
    "# 정상적으로 invoke와 stream 호출\n",
    "print(chat_model.invoke(\"Tell me about AI\"))\n",
    "for chunk in chat_model.stream(\"Tell me about AI\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 채팅 모델에서 Runnable 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming: Tell\n",
      "Streaming: me\n",
      "Streaming: about\n",
      "Streaming: AI\n"
     ]
    }
   ],
   "source": [
    "class ChatModel(Runnable):\n",
    "    def invoke(self, input):\n",
    "        # 채팅 모델이 입력에 대한 응답을 생성\n",
    "        response = f\"Response to {input}\"\n",
    "        return response\n",
    "\n",
    "    def stream(self, input):\n",
    "        # 입력에 대해 응답을 스트리밍\n",
    "        for word in input.split():\n",
    "            yield f\"Streaming: {word}\"\n",
    "\n",
    "# Runnable 인터페이스를 구현한 ChatModel 호출\n",
    "chat_model = ChatModel()\n",
    "result = chat_model.invoke(\"Tell me about AI\")\n",
    "for chunk in chat_model.stream(\"Tell me about AI\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력 파서에서 Runnable 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parsed_output': 'This is a raw output'}\n"
     ]
    }
   ],
   "source": [
    "class OutputParser(Runnable):\n",
    "    def invoke(self, input):\n",
    "        # LLM 또는 채팅 모델의 출력을 파싱하여 구조화된 데이터 반환\n",
    "        return {\"parsed_output\": input}\n",
    "\n",
    "# Runnable 인터페이스를 구현한 OutputParser 호출\n",
    "parser = OutputParser()\n",
    "parsed_result = parser.invoke(\"This is a raw output\")\n",
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리트리버에서 Runnable 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Document related to: Explain AI']\n"
     ]
    }
   ],
   "source": [
    "class Retriever(Runnable):\n",
    "    def invoke(self, query):\n",
    "        # 데이터베이스 또는 문서에서 쿼리에 맞는 정보를 검색\n",
    "        return [f\"Document related to: {query}\"]\n",
    "\n",
    "# Runnable 인터페이스를 구현한 Retriever 호출\n",
    "retriever = Retriever()\n",
    "documents = retriever.invoke(\"Explain AI\")\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프롬프트에서 Runnable 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated prompt: Tell me about AI\n"
     ]
    }
   ],
   "source": [
    "class PromptTemplate(Runnable):\n",
    "    def invoke(self, input):\n",
    "        # 입력을 기반으로 프롬프트 생성\n",
    "        return f\"Generated prompt: {input}\"\n",
    "\n",
    "# Runnable 인터페이스를 구현한 PromptTemplate 호출\n",
    "template = PromptTemplate()\n",
    "prompt = template.invoke(\"Tell me about AI\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Chat 모델 인스턴스 생성\n",
    "chat_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", api_key=\"your-api-key\")\n",
    "\n",
    "# 메시지 기반 대화\n",
    "response = chat_model.invoke(input=\"What is the capital of France?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Human Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 사용자 메시지 생성\n",
    "message = HumanMessage(content=\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# AI 메시지 생성\n",
    "ai_message = AIMessage(content=\"The capital of France is Paris.\", response_metadata={\"logprobs\": [0.1, 0.9]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# 시스템 메시지 생성\n",
    "system_message = SystemMessage(content=\"You are a helpful assistant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# 도구 호출 결과 메시지 생성\n",
    "tool_message = ToolMessage(content=\"The capital of France is Paris.\", tool_call_id=\"12345\", artifact={\"file\": \"output.csv\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prommpt Template의 유형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. String PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Tell me a joke about cats'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 주제에 맞는 농담 생성 프롬프트\n",
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "\n",
    "# 주제 'cats'로 프롬프트 실행\n",
    "response = prompt_template.invoke({\"topic\": \"cats\"})\n",
    "print(response)  # \"Tell me a joke about cats\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a joke about cats', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 시스템 메시지와 사용자 메시지를 포함한 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "\n",
    "# 주제 'cats'로 프롬프트 실행\n",
    "response = prompt_template.invoke({\"topic\": \"cats\"})\n",
    "print(response)  # [\"You are a helpful assistant\", \"Tell me a joke about cats\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 메시지 플레이스홀더 사용한 템플릿\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "\n",
    "# 메시지 리스트를 입력으로 전달\n",
    "response = prompt_template.invoke({\"msgs\": [HumanMessage(content=\"hi!\")]})\n",
    "print(response)  # [\"You are a helpful assistant\", \"hi!\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Selector\n",
    "##### Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Input: {input} -> Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"hi\", \"output\": \"ciao\"},\n",
    "    {\"input\": \"bye\", \"output\": \"arrivaderci\"},\n",
    "    {\"input\": \"soccer\", \"output\": \"calcio\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Custom Example Selector\n",
    "from langchain_core.example_selectors.base import BaseExampleSelector\n",
    "\n",
    "class CustomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        # This assumes knowledge that part of the input will be a 'text' key\n",
    "        new_word = input_variables[\"input\"]\n",
    "        new_word_length = len(new_word)\n",
    "\n",
    "        # Initialize variables to store the best match and its length difference\n",
    "        best_match = None\n",
    "        smallest_diff = float(\"inf\")\n",
    "\n",
    "        # Iterate through each example\n",
    "        for example in self.examples:\n",
    "            # Calculate the length difference with the first word of the example\n",
    "            current_diff = abs(len(example[\"input\"]) - new_word_length)\n",
    "\n",
    "            # Update the best match if the current one is closer in length\n",
    "            if current_diff < smallest_diff:\n",
    "                smallest_diff = current_diff\n",
    "                best_match = example\n",
    "\n",
    "        return [best_match]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = CustomExampleSelector(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following words from English to Italian:\n",
      "\n",
      "Input: bye -> Output: arrivaderci\n",
      "\n",
      "Input: word -> Output:\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Input: {input} -> Output:\",\n",
    "    prefix=\"Translate the following words from English to Italian:\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "print(prompt.format(input=\"word\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following words from English to Italain:\n",
      "\n",
      "Input: bye -> Output: arrivaderci\n",
      "\n",
      "Input: word -> Output:\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Input: {input} -> Output: {output}\")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Input: {input} -> Output:\",\n",
    "    prefix=\"Translate the following words from English to Italain:\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "print(prompt.format(input=\"word\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser\n",
    "1. JSON Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice', 'age': 30}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# JSON 출력 파서 사용\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "# 예시 출력 텍스트\n",
    "output = '{\"name\": \"Alice\", \"age\": 30}'\n",
    "\n",
    "# JSON 객체로 변환\n",
    "parsed_output = output_parser.parse(output)\n",
    "print(parsed_output)  # {\"name\": \"Alice\", \"age\": 30}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. XML Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'person': [{'name': 'Alice'}, {'age': '30'}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "\n",
    "# XML 출력 파서 사용\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "# 예시 출력 텍스트\n",
    "output = '<person><name>Alice</name><age>30</age></person>'\n",
    "\n",
    "# XML 사전으로 변환\n",
    "parsed_output = output_parser.parse(output)\n",
    "print(parsed_output)  # {\"person\": {\"name\": \"Alice\", \"age\": 30}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is AI?\n",
      "AI stands for Artificial Intelligence.\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "# ChatHistory 인스턴스 생성\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "# 대화 기록 추가\n",
    "history.add_user_message(\"What is AI?\")\n",
    "history.add_ai_message(\"AI stands for Artificial Intelligence.\")\n",
    "\n",
    "# 대화 기록 불러오기\n",
    "messages = history.messages\n",
    "for message in messages:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the content of the document.\n",
      "{'id': 123, 'file_name': 'example.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Document 객체 생성\n",
    "doc = Document(page_content=\"This is the content of the document.\", metadata={\"id\": 123, \"file_name\": \"example.txt\"})\n",
    "\n",
    "# 내용과 메타데이터 출력\n",
    "print(doc.page_content)  # 문서 내용\n",
    "print(doc.metadata)      # 문서 메타데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# CSVLoader 인스턴스 생성\n",
    "loader = CSVLoader(\n",
    "    file_path=\"example.csv\"  # CSV 파일 경로\n",
    ")\n",
    "\n",
    "# CSV 파일 로드하여 Document 객체로 반환\n",
    "documents = loader.load()\n",
    "\n",
    "# 로드된 문서 출력\n",
    "for doc in documents:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Character Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a long document that needs to be split int\n",
      "split into smaller chunks for processing.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# CharacterTextSplitter 설정\n",
    "text_splitter = CharacterTextSplitter(separator='', chunk_size=50, chunk_overlap=10)\n",
    "\n",
    "# 예시 문서 텍스트\n",
    "text = \"This is a long document that needs to be split into smaller chunks for processing.\"\n",
    "\n",
    "# 텍스트를 청크로 분할\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Recursive Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a long document that needs to be split\n",
      "be split into smaller chunks for processing.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# CharacterTextSplitter 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "\n",
    "# 예시 문서 텍스트\n",
    "text = \"This is a long document that needs to be split into smaller chunks for processing.\"\n",
    "\n",
    "# 텍스트를 청크로 분할\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
